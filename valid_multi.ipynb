{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import os\n",
    "os.sys.path.append('..')\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"]=\"0\"\n",
    "import torch\n",
    "from torch.autograd import Variable\n",
    "from torchvision import datasets, transforms\n",
    "from scipy.misc import imsave\n",
    "import scipy.io\n",
    "import warnings\n",
    "import sys\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "import matplotlib.pyplot as plt\n",
    "import scipy.misc\n",
    "\n",
    "from darknet_multi import Darknet\n",
    "from utils import *\n",
    "import dataset_multi\n",
    "from MeshPly import MeshPly"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors_pr = [( 83, 270,  73),(0,0,0),\n",
    "( 82, 285, 253),\n",
    "(175,  56,  43),\n",
    "(124, 412, 482),\n",
    "(343, 219, 204),\n",
    "( 53, 458, 231),\n",
    "(215,  70, 304),\n",
    "( 46, 164, 149),\n",
    "(272,  94,  69)]\n",
    "colors_gt = [(246, 194,  53),(0,0,0),\n",
    " ( 95, 230,   4),\n",
    " ( 92,  46, 190),\n",
    " (343, 559, 168),\n",
    " (122,  70, 313),\n",
    " (151, 302, 342),\n",
    " (2,  87, 134),\n",
    " (131, 549, 198),\n",
    "(356,  27, 233)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "colors = abs(np.random.randn(9,3))*255\n",
    "colors = colors.astype('int')\n",
    "print(colors)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "def draw(im, pts, c, draw_pairs):\n",
    "    '''draw skeleton and mark joints using joint_id, depend on opencv'''\n",
    "    img=im.copy()\n",
    "    for pair in draw_pairs:\n",
    "        i,j = pair\n",
    "        x1=int(pts[i,0])\n",
    "        x2=int(pts[j,0])\n",
    "        y1=int(pts[i,1])\n",
    "        y2=int(pts[j,1])\n",
    "        if x1>0 and x2>0 and y1>0 and y2>0:\n",
    "            img=cv2.line(img,(x1, y1), (x2, y2),tuple(c),3)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def valid(datacfg, cfgfile, weightfile, conf_th):\n",
    "    def truths_length(truths):\n",
    "        for i in range(50):\n",
    "            if truths[i][1] == 0:\n",
    "                return i\n",
    "\n",
    "    # Parse configuration files\n",
    "    options       = read_data_cfg(datacfg)\n",
    "    valid_images  = options['valid']\n",
    "    meshname      = options['mesh']\n",
    "    name          = options['name']\n",
    "    prefix        = 'results'\n",
    "    # Read object model information, get 3D bounding box corners\n",
    "    mesh          = MeshPly(meshname)\n",
    "    objs_ape = { 'can':3, 'cat':4, 'driller':5, 'duck':6, 'eggbox':7,'glue':8, 'holepuncher':9}\n",
    "    vertices      = np.c_[np.array(mesh.vertices), np.ones((len(mesh.vertices), 1))].transpose()\n",
    "    corners3D     = get_3D_corners(vertices)\n",
    "    corners = {0:corners3D.copy()}\n",
    "    for obj in objs_ape.keys():\n",
    "        mesh = MeshPly(meshname.replace('ape',obj))\n",
    "        vertices      = np.c_[np.array(mesh.vertices), np.ones((len(mesh.vertices), 1))].transpose()\n",
    "        corners3D     = get_3D_corners(vertices)\n",
    "        corners[objs_ape[obj]] = corners3D.copy()\n",
    "    # Read intrinsic camera parameters\n",
    "    internal_calibration = get_camera_intrinsic()\n",
    "\n",
    "    # Get validation file names\n",
    "    with open(valid_images) as fp:\n",
    "        tmp_files = fp.readlines()\n",
    "        valid_files = [item.rstrip() for item in tmp_files]\n",
    "    \n",
    "    # Specicy model, load pretrained weights, pass to GPU and set the module in evaluation mode\n",
    "    model = Darknet(cfgfile)\n",
    "    model.load_weights(weightfile)\n",
    "    model.cuda()\n",
    "    model.eval()\n",
    "\n",
    "    # Get the parser for the test dataset\n",
    "    valid_dataset = dataset_multi.listDataset_multi(valid_images, shape=(model.width, model.height),\n",
    "                       shuffle=False,\n",
    "                       objclass=name,\n",
    "                       transform=transforms.Compose([\n",
    "                           transforms.ToTensor(),\n",
    "                       ]))\n",
    "    valid_batchsize = 1\n",
    "\n",
    "    # Specify the number of workers for multiple processing, get the dataloader for the test dataset\n",
    "    kwargs = {'num_workers': 4, 'pin_memory': True}\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        valid_dataset, batch_size=1, shuffle=False, **kwargs) \n",
    "\n",
    "    # Parameters\n",
    "    visualize       = True\n",
    "    use_cuda        = True\n",
    "    num_classes     = 13\n",
    "    anchors         = [1.4820, 2.2412, 2.0501, 3.1265, 2.3946, 4.6891, 3.1018, 3.9910, 3.4879, 5.8851]\n",
    "    num_anchors     = 5\n",
    "    eps             = 1e-5\n",
    "    conf_thresh     = conf_th\n",
    "    iou_thresh      = 0.5\n",
    "\n",
    "    # Parameters to save\n",
    "    errs_2d = []\n",
    "    edges = [[1, 2], [1, 3], [1, 5], [2, 4], [2, 6], [3, 4], [3, 7], [4, 8], [5, 6], [5, 7], [6, 8], [7, 8]]\n",
    "    edges_corners = [[0, 1], [0, 2], [0, 4], [1, 3], [1, 5], [2, 3], [2, 6], [3, 7], [4, 5], [4, 6], [5, 7], [6, 7]]\n",
    "\n",
    "    # Iterate through test batches (Batch size for test data is 1)\n",
    "    count = 0\n",
    "    logging('Testing {}...'.format(name))\n",
    "    test = list(enumerate(test_loader))\n",
    "    k = 407#int((np.random.rand(1)*len(test))[0])\n",
    "    errmin =1000\n",
    "    errk = 0\n",
    "    for batch_idx, (data, target) in test[k:k+1]:\n",
    "        \n",
    "        img = data[0, :, :, :]\n",
    "        img = img.numpy().squeeze()\n",
    "        img = np.transpose(img, (1, 2, 0))\n",
    "        img_ = scipy.misc.imresize(img, (480, 640))\n",
    "        img_gt = img_.copy()\n",
    "        img_pr = img_.copy()\n",
    "        t1 = time.time()\n",
    "        # Pass data to GPU\n",
    "        if use_cuda:\n",
    "            data = data.cuda()\n",
    "        \n",
    "        # Wrap tensors in Variable class, set volatile=True for inference mode and to use minimal memory during inference\n",
    "        with torch.no_grad():\n",
    "            data = Variable(data)\n",
    "        t2 = time.time()\n",
    "        \n",
    "        # Forward pass\n",
    "        output = model(data).data.cpu()  \n",
    "        t3 = time.time()\n",
    "        \n",
    "        # Using confidence threshold, eliminate low-confidence predictions\n",
    "        trgt = target[0].view(-1, 21)\n",
    "        all_boxes = get_corresponding_region_boxes(output, conf_thresh, num_classes, anchors, num_anchors, int(trgt[0][0]), only_objectness=0)        \n",
    "        t4 = time.time()\n",
    "        # Iterate through all images in the batch\n",
    "        for i in range(output.size(0)):\n",
    "            \n",
    "            # For each image, get all the predictions\n",
    "            boxes   = all_boxes[i]\n",
    "            \n",
    "            # For each image, get all the targets (for multiple object pose estimation, there might be more than 1 target per image)\n",
    "            truths  = target[i].view(-1, 21)\n",
    "            \n",
    "            # Get how many object are present in the scene\n",
    "            num_gts = truths_length(truths)\n",
    "            err = 0\n",
    "\n",
    "            # Iterate through each ground-truth object\n",
    "            for k in range(num_gts):\n",
    "                box_gt        = [truths[k][1], truths[k][2], truths[k][3], truths[k][4], truths[k][5], truths[k][6], \n",
    "                                truths[k][7], truths[k][8], truths[k][9], truths[k][10], truths[k][11], truths[k][12], \n",
    "                                truths[k][13], truths[k][14], truths[k][15], truths[k][16], truths[k][17], truths[k][18], 1.0, 1.0, truths[k][0]]\n",
    "                best_conf_est = -1\n",
    "                cls = int(truths[k][0])\n",
    "                if cls ==7:\n",
    "                    continue\n",
    "                corners3D = corners[cls]\n",
    "                # If the prediction has the highest confidence, choose it as our prediction\n",
    "                for j in range(len(boxes)):\n",
    "                    if (boxes[j][18] > best_conf_est) and (boxes[j][20] == int(truths[k][0])):\n",
    "                        best_conf_est = boxes[j][18]\n",
    "                        box_pr        = boxes[j]\n",
    "                        bb2d_gt       = get_2d_bb(box_gt[:18], output.size(3))\n",
    "                        bb2d_pr       = get_2d_bb(box_pr[:18], output.size(3))\n",
    "                        iou           = bbox_iou(bb2d_gt, bb2d_pr)\n",
    "                        match         = corner_confidence9(box_gt[:18], torch.FloatTensor(boxes[j][:18]))   \n",
    "                # Denormalize the corner predictions \n",
    "                corners2D_gt = np.array(np.reshape(box_gt[:18], [9, 2]), dtype='float32')\n",
    "                corners2D_pr = np.array(np.reshape(box_pr[:18], [9, 2]), dtype='float32')\n",
    "                corners2D_gt[:, 0] = corners2D_gt[:, 0] * 640\n",
    "                corners2D_gt[:, 1] = corners2D_gt[:, 1] * 480               \n",
    "                corners2D_pr[:, 0] = corners2D_pr[:, 0] * 640\n",
    "                corners2D_pr[:, 1] = corners2D_pr[:, 1] * 480\n",
    "                corners2D_gt_corrected = fix_corner_order(corners2D_gt) # Fix the order of the corners in OCCLUSION\n",
    "                \n",
    "                # Compute [R|t] by pnp\n",
    "                objpoints3D = np.array(np.transpose(np.concatenate((np.zeros((3, 1)), corners3D[:3, :]), axis=1)), dtype='float32')\n",
    "                K = np.array(internal_calibration, dtype='float32')\n",
    "                R_gt, t_gt = pnp(objpoints3D,  corners2D_gt_corrected, K)\n",
    "                R_pr, t_pr = pnp(objpoints3D,  corners2D_pr, K)\n",
    "                \n",
    "                # Compute pixel error\n",
    "                Rt_gt        = np.concatenate((R_gt, t_gt), axis=1)\n",
    "                Rt_pr        = np.concatenate((R_pr, t_pr), axis=1)\n",
    "                proj_2d_gt   = compute_projection(vertices, Rt_gt, internal_calibration) \n",
    "                proj_2d_pred = compute_projection(vertices, Rt_pr, internal_calibration) \n",
    "                proj_corners_gt = np.transpose(compute_projection(corners3D, Rt_gt, internal_calibration)) \n",
    "                proj_corners_pr = np.transpose(compute_projection(corners3D, Rt_pr, internal_calibration)) \n",
    "                norm         = np.linalg.norm(proj_2d_gt - proj_2d_pred, axis=0)\n",
    "                pixel_dist   = np.mean(norm)\n",
    "                err +=pixel_dist\n",
    "                img_pr = draw(img_pr,proj_corners_pr,colors_pr[cls],edges_corners)\n",
    "                img_gt = draw(img_gt,proj_corners_gt,colors_gt[cls],edges_corners)\n",
    "                img_obj = draw(img_,proj_corners_pr,colors_pr[cls],edges_corners)\n",
    "                img_obj = draw(img_obj,proj_corners_gt,colors_gt[cls],edges_corners)\n",
    "                plt.figure()\n",
    "                plt.imshow(img_obj)\n",
    "                print(cls)\n",
    "                cv2.imwrite('res/img_'+str(cls)+'.png',img_obj)\n",
    "\n",
    "                \n",
    "                '''if visualize:\n",
    "                    plt.figure()\n",
    "                    # Visualize\n",
    "                    plt.axis('off')\n",
    "                    plt.xlim((0, 640))\n",
    "                    plt.ylim((0, 480))\n",
    "                    plt.imshow(scipy.misc.imresize(img, (480, 640)))\n",
    "                    plt.gca().invert_yaxis()\n",
    "                    plt.figure()\n",
    "                    plt.axis('off')\n",
    "                    # Visualize\n",
    "                    plt.xlim((0, 640))\n",
    "                    plt.ylim((0, 480))\n",
    "                    plt.imshow(scipy.misc.imresize(img, (480, 640)))\n",
    "                    # Projections\n",
    "                    for edge in edges_corners:\n",
    "                        plt.plot(proj_corners_gt[edge, 0], proj_corners_gt[edge, 1], color='y', linewidth=3.0)\n",
    "                        plt.plot(proj_corners_pr[edge, 0], proj_corners_pr[edge, 1], color='b', linewidth=2.0)\n",
    "                    plt.gca().invert_yaxis()'''\n",
    "                    \n",
    "            plt.figure()\n",
    "            plt.imshow(img_pr)\n",
    "            cv2.imwrite('res/img_pr.png',img_pr)\n",
    "            plt.figure()\n",
    "            plt.imshow(img_gt)\n",
    "            cv2.imwrite('res/img_gt.png',img_gt)\n",
    "            '''\n",
    "            err /=num_gts\n",
    "            if err<errmin:\n",
    "                errmin = err\n",
    "                errk = batch_idx'''\n",
    "\n",
    "        t5 = time.time()\n",
    "    print(errk)\n",
    "\n",
    "\n",
    "conf_th = 0.3\n",
    "cfgfile = 'cfg/yolo-pose-multi.cfg'\n",
    "weightfile = '../checkpoint_multi/yolo-pose-multi-no-ohkm/model.weights'\n",
    "datacfg = 'cfg/ape_occlusion.data'\n",
    "valid(datacfg, cfgfile, weightfile, conf_th)\n",
    "'''datacfg = 'cfg/can_occlusion.data'\n",
    "valid(datacfg, cfgfile, weightfile, conf_th)\n",
    "datacfg = 'cfg/cat_occlusion.data'\n",
    "valid(datacfg, cfgfile, weightfile, conf_th)\n",
    "datacfg = 'cfg/duck_occlusion.data'\n",
    "valid(datacfg, cfgfile, weightfile, conf_th)\n",
    "datacfg = 'cfg/driller_occlusion.data'\n",
    "valid(datacfg, cfgfile, weightfile, conf_th)\n",
    "datacfg = 'cfg/glue_occlusion.data'\n",
    "valid(datacfg, cfgfile, weightfile, conf_th)\n",
    "datacfg = 'cfg/holepuncher_occlusion.data'\n",
    "valid(datacfg, cfgfile, weightfile, conf_th)'''\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}